% Communication is anchored to the material world, to space, to events and people. One way it gets anchored is through pointing. 


Enabling robots to understand and generate instructions to collaboratively solve tasks with humans is an active area of research in natural language processing and human-robot interaction.
Roboticists have indentified the importance of pointing actions in the context of conveying the intent of motions generated by robotic manipulators. Legibility was used as a metric to devise cost functions, and generate motions without speech \cite{zhao2016experimental,holladay2014legible}.
These studies proposed rigid models that treats the objective of communication of the object a robot is about to pick as one of the optimization criteria.
The current work studies the inherent flexibility of vague pointing gestures towards both referent objects and parts of the space, in communicating an entire pick-and-place task.

Other lines of work have looked at pointing as a way of helping the robot to navigate in space. This models the discrimination of direction, i.e, left, or right etc. Tasks involving placing objects on the table require the specification of the exact spatial location which has not been discussed in these studies. \cite{mei2016listen,tellex2011understanding}


In natural language processing, people have studied understanding and generation of multimodal referring expressions. This involves studying the generation of referring expressions together with the pointing action to pick a target referent. For instance,  \cite{kollar2014grounding,han2018placing} have shown how and when natural language is efficient for constructing spatial-semantic representations of known environments. \cite{kennington2013interpreting} proposed a discriminative model of incremental reference resolution. The focus of these studies is on designing models for generating referring expression for a target object. 
% These works do not investigate the difference between the richness of intents that pointing can express that we study in this paper. 
This is true about cognitive and linguistics studies as well \cite{kita2003pointing,kita2003interplay,clark2003pointing,goodwin2003pointing}.
% Pointing has been the subject of cognitive and linguistics studies as a situated practice \cite{kita2003pointing,kita2003interplay,clark2003pointing,goodwin2003pointing}.
They have relaxed the model of the pointing ray by introducing the pointing cone. 
The pointing cone model specifies that the target of pointing action has to fall into the cone that comes out of the pointing finger \cite{rieser2004pointing,kranstedt2003deixis}. These studies do not narrow down a generative process that is necessary in the context of human robot interaction. Moreover, they do not investigate the difference between the richness of intents that pointing can express that we study in this paper.

Our work however, proposes a new challenge. It considers the problem of a robot performing pointing actions to communicate a pick-and-place task to a human observer. This involves pointing to identify object placement in space which has been mainly overlooked by the previous literature. Furthermore, this work proposes that picking is more flexible compared to the rigid models proposed by prior work. We also study the effects of common ground and perspective on domains of referential interpretation. We present experiments testing our hypothesis. Evaluations on two different robotic arms, which are visually distinct, indicate the applicability of our hypothesis in general robotic pointing tasks.

% These works require a semantically labeled representation of the environment.













